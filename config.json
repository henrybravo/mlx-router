{
    "defaults": {
      "max_tokens": 8192,
      "timeout": 120,
      "cache_size": 2,
      "memory_threshold_gb": 90.0,
      "stream": false,
      "model": "mlx-community/Llama-3.3-70B-Instruct-4bit",
      "stream_chunk_size": 32,
      "warmup_tokens": 5,
      "enable_function_calling": true,
      "model_directory": "/Users/username/models"
    },
    "server": {
        "ip": "0.0.0.0",
        "port": 8800,
        "debug": true
    },
    "models": {
        "mlx-community/Llama-3.3-70B-Instruct-4bit": {
            "max_tokens": 8192,
            "temp": 0.7,
            "top_p": 0.95,
            "top_k": 50,
            "min_p": 0.05,
            "chat_template": "llama3",
            "required_memory_gb": 40,
            "supports_tools": true,
            "memory_pressure_max_tokens": {
                "normal": 4096,
                "moderate": 2048,
                "high": 1024,
                "critical": 512
            }
        },
        "deepseek-ai/deepseek-coder-6.7b-instruct": {
            "max_tokens": 4096,
            "temp": 0.1,
            "top_p": 0.95,
            "top_k": 20,
            "min_p": 0.1,
            "chat_template": "deepseek",
            "required_memory_gb": 8,
            "supports_tools": true,
            "memory_pressure_max_tokens": {
                "normal": 4096,
                "moderate": 2048,
                "high": 1024,
                "critical": 512
            }
        },
        "mlx-community/Phi-4-reasoning-plus-6bit": {
            "max_tokens": 4096,
            "temp": 0.3,
            "top_p": 0.9,
            "top_k": 25,
            "min_p": 0.08,
            "chat_template": "phi4",
            "required_memory_gb": 12,
            "supports_tools": true,
            "memory_pressure_max_tokens": {
                "normal": 4096,
                "moderate": 2048,
                "high": 1024,
                "critical": 512
            }
        },
        "mlx-community/Qwen3-30B-A3B-8bit": {
            "max_tokens": 8192,
            "temp": 0.7,
            "top_p": 0.9,
            "top_k": 40,
            "min_p": 0.05,
            "chat_template": "qwen",
            "required_memory_gb": 18,
            "supports_tools": true,
            "memory_pressure_max_tokens": {
                "normal": 4096,
                "moderate": 2048,
                "high": 1024,
                "critical": 512
            }
        }
    }
}
