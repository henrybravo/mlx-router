{
    "mlx-community/gpt-oss-120b-MXFP4-Q8": {
        "max_tokens": 4096,
        "temp": 0.7,
        "top_p": 0.9,
        "top_k": 40,
        "min_p": 0.05,
        "chat_template": "gpt-oss",
        "required_memory_gb": 8,
        "memory_pressure_max_tokens": {
            "normal": 4096,
            "moderate": 2048,
            "high": 1024,
            "critical": 512
        }
    }
}